{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# NFL Network-Based Team Strength Analysis\n",
    "\n",
    "## Objective\n",
    "Implement network-based strength propagation for team tier classification:\n",
    "- **Iterative Strength Ratings**: Massey/PageRank-style algorithm\n",
    "- **Network-Weighted SOS**: Strength of schedule using network ratings\n",
    "- **Multi-Hop Common Opponents**: 2-level transitive relationships\n",
    "\n",
    "## NFL-Specific Characteristics\n",
    "- 32 teams, 17-game regular season\n",
    "- Dense graph (every team plays ~50% of league)\n",
    "- Strong conference/division structure\n",
    "- Parameters: `max_hops=2`, `recency_decay=0.9`, `margin_cap=21`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# NFL-specific config\n",
    "CONFIG = {\n",
    "    'sport': 'NFL',\n",
    "    'max_hops': 2,          # Dense graph, limit hops\n",
    "    'recency_decay': 0.9,   # Recent games important\n",
    "    'margin_cap': 21,       # 3 TDs max impact\n",
    "    'iterations': 100,\n",
    "    'tolerance': 0.001\n",
    "}\n",
    "\n",
    "print(f\"Config: {CONFIG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Phase 1: Data Loading & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NFL data\n",
    "data_file = Path().resolve().parent / 'data' / 'results' / 'nfl_season_results.xlsx'\n",
    "df = pd.read_excel(data_file)\n",
    "\n",
    "print(f\"Loaded {len(df)} NFL games\")\n",
    "print(f\"Date range: {df['game_date'].min().date()} to {df['game_date'].max().date()}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prep-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare game-level data with winner/loser/margin\n",
    "df['home_margin'] = df['home_score'] - df['away_score']\n",
    "df['winner'] = np.where(df['home_margin'] > 0, df['home_team'], \n",
    "                        np.where(df['home_margin'] < 0, df['away_team'], None))\n",
    "df['loser'] = np.where(df['home_margin'] > 0, df['away_team'], \n",
    "                       np.where(df['home_margin'] < 0, df['home_team'], None))\n",
    "df['margin'] = df['home_margin'].abs()\n",
    "\n",
    "# Drop ties (if any)\n",
    "games_with_result = df[df['winner'].notna()].copy()\n",
    "print(f\"Games with decisive result: {len(games_with_result)} (dropped {len(df) - len(games_with_result)} ties)\")\n",
    "\n",
    "# Get all teams\n",
    "all_teams = set(df['home_team'].unique()) | set(df['away_team'].unique())\n",
    "print(f\"Total teams: {len(all_teams)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graph-header",
   "metadata": {},
   "source": [
    "## Phase 2: Build Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_team_network(games_df, recency_decay=0.9):\n",
    "    \"\"\"\n",
    "    Build weighted directed graph from game results.\n",
    "    \n",
    "    Nodes: Teams\n",
    "    Edges: Winner -> Loser with weight = margin (recency-weighted)\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add all teams as nodes\n",
    "    for team in all_teams:\n",
    "        G.add_node(team)\n",
    "    \n",
    "    # Sort by date for recency weighting\n",
    "    games_sorted = games_df.sort_values('game_date')\n",
    "    max_date = games_sorted['game_date'].max()\n",
    "    \n",
    "    # Build edge data\n",
    "    edge_data = {}\n",
    "    \n",
    "    for _, game in games_sorted.iterrows():\n",
    "        winner, loser = game['winner'], game['loser']\n",
    "        margin = game['margin']\n",
    "        \n",
    "        # Calculate recency weight (exponential decay)\n",
    "        days_ago = (max_date - game['game_date']).days\n",
    "        recency_weight = recency_decay ** (days_ago / 7)  # Weekly decay\n",
    "        \n",
    "        key = (winner, loser)\n",
    "        if key not in edge_data:\n",
    "            edge_data[key] = {\n",
    "                'games': 0,\n",
    "                'total_margin': 0,\n",
    "                'weighted_margin': 0,\n",
    "                'total_weight': 0\n",
    "            }\n",
    "        \n",
    "        edge_data[key]['games'] += 1\n",
    "        edge_data[key]['total_margin'] += margin\n",
    "        edge_data[key]['weighted_margin'] += margin * recency_weight\n",
    "        edge_data[key]['total_weight'] += recency_weight\n",
    "    \n",
    "    # Add edges to graph\n",
    "    for (winner, loser), data in edge_data.items():\n",
    "        avg_margin = data['total_margin'] / data['games']\n",
    "        weighted_avg = data['weighted_margin'] / data['total_weight']\n",
    "        \n",
    "        G.add_edge(winner, loser, \n",
    "                   games=data['games'],\n",
    "                   avg_margin=avg_margin,\n",
    "                   weighted_margin=weighted_avg)\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Build the network\n",
    "G = build_team_network(games_with_result, CONFIG['recency_decay'])\n",
    "\n",
    "print(f\"Network Summary:\")\n",
    "print(f\"  Nodes (teams): {G.number_of_nodes()}\")\n",
    "print(f\"  Edges (winner->loser): {G.number_of_edges()}\")\n",
    "print(f\"  Avg out-degree (wins): {sum(dict(G.out_degree()).values()) / G.number_of_nodes():.1f}\")\n",
    "print(f\"  Density: {nx.density(G):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-graph",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize the network (top teams highlighted)\nfig, ax = plt.subplots(figsize=(14, 14))\n\n# Calculate simple win percentage for coloring\nwin_counts = dict(G.out_degree())\nloss_counts = dict(G.in_degree())\nwin_pct = {team: win_counts.get(team, 0) / (win_counts.get(team, 0) + loss_counts.get(team, 0) + 0.001)\n           for team in all_teams}\n\n# Node colors based on win%\nnode_colors = [win_pct.get(node, 0.5) for node in G.nodes()]\n\n# Layout\npos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n\n# Draw\nnodes = nx.draw_networkx_nodes(G, pos, node_color=node_colors, cmap=plt.cm.RdYlGn,\n                               node_size=500, alpha=0.8, vmin=0.2, vmax=0.8, ax=ax)\nnx.draw_networkx_labels(G, pos, font_size=7, ax=ax)\nnx.draw_networkx_edges(G, pos, alpha=0.15, arrows=True,\n                       edge_color='gray', arrowsize=10, ax=ax)\n\nax.set_title(f'NFL Team Network (Edge: Winner -> Loser)\\nNode color: Win %', fontsize=14)\nfig.colorbar(nodes, ax=ax, label='Win %')\nax.axis('off')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "strength-header",
   "metadata": {},
   "source": [
    "## Phase 3: Iterative Strength Rating (Massey-Style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strength-algo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iterative_strength(games_df, max_iterations=100, tolerance=0.001, margin_cap=21):\n",
    "    \"\"\"\n",
    "    Compute network-propagated team strength ratings.\n",
    "    \n",
    "    Algorithm:\n",
    "    1. Initialize all teams with rating = 0.5\n",
    "    2. For each game:\n",
    "       - Expected outcome based on current ratings\n",
    "       - Surprise factor = 1 - expected\n",
    "       - Adjustment = surprise * margin (capped)\n",
    "       - Winner rating += adjustment, Loser -= adjustment\n",
    "    3. Normalize to [0, 1]\n",
    "    4. Repeat until convergence\n",
    "    \"\"\"\n",
    "    # Get unique teams\n",
    "    teams = set(games_df['home_team']) | set(games_df['away_team'])\n",
    "    \n",
    "    # Initialize ratings\n",
    "    ratings = {team: 0.5 for team in teams}\n",
    "    \n",
    "    # Filter to games with results\n",
    "    games = games_df[games_df['winner'].notna()].copy()\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        new_ratings = ratings.copy()\n",
    "        \n",
    "        for _, game in games.iterrows():\n",
    "            winner = game['winner']\n",
    "            loser = game['loser']\n",
    "            margin = min(game['margin'], margin_cap)  # Cap margin\n",
    "            \n",
    "            winner_rating = ratings[winner]\n",
    "            loser_rating = ratings[loser]\n",
    "            \n",
    "            # Expected outcome (winner should have higher rating)\n",
    "            # Avoid division by zero\n",
    "            total = winner_rating + loser_rating\n",
    "            if total == 0:\n",
    "                expected = 0.5\n",
    "            else:\n",
    "                expected = winner_rating / total\n",
    "            \n",
    "            # Surprise factor (upset = larger surprise)\n",
    "            surprise = 1 - expected\n",
    "            \n",
    "            # Adjustment scaled by margin\n",
    "            adjustment = surprise * (margin / margin_cap) * 0.1\n",
    "            \n",
    "            new_ratings[winner] += adjustment\n",
    "            new_ratings[loser] -= adjustment\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        min_r = min(new_ratings.values())\n",
    "        max_r = max(new_ratings.values())\n",
    "        if max_r > min_r:\n",
    "            new_ratings = {t: (r - min_r) / (max_r - min_r) for t, r in new_ratings.items()}\n",
    "        \n",
    "        # Check convergence\n",
    "        max_change = max(abs(new_ratings[t] - ratings[t]) for t in teams)\n",
    "        history.append(max_change)\n",
    "        \n",
    "        if max_change < tolerance:\n",
    "            print(f\"Converged at iteration {iteration + 1}\")\n",
    "            break\n",
    "        \n",
    "        ratings = new_ratings\n",
    "    \n",
    "    return ratings, history\n",
    "\n",
    "# Compute ratings\n",
    "network_ratings, convergence_history = compute_iterative_strength(\n",
    "    df, \n",
    "    max_iterations=CONFIG['iterations'],\n",
    "    tolerance=CONFIG['tolerance'],\n",
    "    margin_cap=CONFIG['margin_cap']\n",
    ")\n",
    "\n",
    "# Display top teams\n",
    "ratings_df = pd.DataFrame([\n",
    "    {'team': team, 'network_rating': rating}\n",
    "    for team, rating in network_ratings.items()\n",
    "]).sort_values('network_rating', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Teams by Network Rating:\")\n",
    "print(ratings_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convergence\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(convergence_history)\n",
    "plt.axhline(y=CONFIG['tolerance'], color='r', linestyle='--', label=f\"Tolerance ({CONFIG['tolerance']})\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Max Rating Change')\n",
    "plt.title('Convergence of Iterative Strength Algorithm')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation-header",
   "metadata": {},
   "source": [
    "## Phase 4: Validate Ratings vs Simple Win %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calc-simple-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate simple team stats\n",
    "team_stats = []\n",
    "for team in all_teams:\n",
    "    home_games = df[df['home_team'] == team]\n",
    "    away_games = df[df['away_team'] == team]\n",
    "    \n",
    "    home_wins = (home_games['home_score'] > home_games['away_score']).sum()\n",
    "    away_wins = (away_games['away_score'] > away_games['home_score']).sum()\n",
    "    \n",
    "    home_diff = (home_games['home_score'] - home_games['away_score']).sum()\n",
    "    away_diff = (away_games['away_score'] - away_games['home_score']).sum()\n",
    "    \n",
    "    total_games = len(home_games) + len(away_games)\n",
    "    \n",
    "    # Simple SOS: average opponent win%\n",
    "    opponents = list(home_games['away_team']) + list(away_games['home_team'])\n",
    "    \n",
    "    team_stats.append({\n",
    "        'team': team,\n",
    "        'games': total_games,\n",
    "        'wins': home_wins + away_wins,\n",
    "        'simple_win_pct': (home_wins + away_wins) / total_games if total_games > 0 else 0,\n",
    "        'point_diff_avg': (home_diff + away_diff) / total_games if total_games > 0 else 0,\n",
    "        'network_rating': network_ratings.get(team, 0.5),\n",
    "        'opponents': opponents\n",
    "    })\n",
    "\n",
    "df_teams = pd.DataFrame(team_stats)\n",
    "\n",
    "# Calculate simple SOS (avg opponent win%)\n",
    "win_pct_map = df_teams.set_index('team')['simple_win_pct'].to_dict()\n",
    "df_teams['simple_sos'] = df_teams['opponents'].apply(\n",
    "    lambda opps: np.mean([win_pct_map.get(o, 0.5) for o in opps])\n",
    ")\n",
    "\n",
    "# Calculate network SOS (avg opponent network rating)\n",
    "df_teams['network_sos'] = df_teams['opponents'].apply(\n",
    "    lambda opps: np.mean([network_ratings.get(o, 0.5) for o in opps])\n",
    ")\n",
    "\n",
    "df_teams = df_teams.drop('opponents', axis=1).sort_values('network_rating', ascending=False)\n",
    "df_teams.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-ratings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "corr_win_pct = df_teams['network_rating'].corr(df_teams['simple_win_pct'])\n",
    "corr_point_diff = df_teams['network_rating'].corr(df_teams['point_diff_avg'])\n",
    "corr_sos = df_teams['network_sos'].corr(df_teams['simple_sos'])\n",
    "\n",
    "print(\"Correlation Analysis:\")\n",
    "print(f\"  Network Rating vs Win%: {corr_win_pct:.3f}\")\n",
    "print(f\"  Network Rating vs Point Diff: {corr_point_diff:.3f}\")\n",
    "print(f\"  Network SOS vs Simple SOS: {corr_sos:.3f}\")\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].scatter(df_teams['simple_win_pct'], df_teams['network_rating'], alpha=0.7)\n",
    "axes[0].set_xlabel('Simple Win %')\n",
    "axes[0].set_ylabel('Network Rating')\n",
    "axes[0].set_title(f'Network Rating vs Win % (r={corr_win_pct:.3f})')\n",
    "z = np.polyfit(df_teams['simple_win_pct'], df_teams['network_rating'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[0].plot(df_teams['simple_win_pct'].sort_values(), p(df_teams['simple_win_pct'].sort_values()), 'r--')\n",
    "\n",
    "axes[1].scatter(df_teams['point_diff_avg'], df_teams['network_rating'], alpha=0.7)\n",
    "axes[1].set_xlabel('Avg Point Differential')\n",
    "axes[1].set_ylabel('Network Rating')\n",
    "axes[1].set_title(f'Network Rating vs Point Diff (r={corr_point_diff:.3f})')\n",
    "\n",
    "axes[2].scatter(df_teams['simple_sos'], df_teams['network_sos'], alpha=0.7)\n",
    "axes[2].set_xlabel('Simple SOS (Opp Win%)')\n",
    "axes[2].set_ylabel('Network SOS (Opp Network Rating)')\n",
    "axes[2].set_title(f'Network SOS vs Simple SOS (r={corr_sos:.3f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tier-header",
   "metadata": {},
   "source": [
    "## Phase 5: Network-Based Tier Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classify-tiers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify tiers using network rating vs simple win%\n",
    "q75_simple, q25_simple = df_teams['simple_win_pct'].quantile([0.75, 0.25])\n",
    "q75_network, q25_network = df_teams['network_rating'].quantile([0.75, 0.25])\n",
    "\n",
    "df_teams['simple_tier'] = df_teams['simple_win_pct'].apply(\n",
    "    lambda x: 'Elite' if x >= q75_simple else ('Bottom' if x <= q25_simple else 'Mid')\n",
    ")\n",
    "df_teams['network_tier'] = df_teams['network_rating'].apply(\n",
    "    lambda x: 'Elite' if x >= q75_network else ('Bottom' if x <= q25_network else 'Mid')\n",
    ")\n",
    "\n",
    "print(\"Tier Classification Comparison:\")\n",
    "print(f\"\\nSimple (Win%) thresholds: Elite >= {q75_simple:.3f}, Bottom <= {q25_simple:.3f}\")\n",
    "print(f\"Network thresholds: Elite >= {q75_network:.3f}, Bottom <= {q25_network:.3f}\")\n",
    "\n",
    "# Agreement matrix\n",
    "agreement = pd.crosstab(df_teams['simple_tier'], df_teams['network_tier'], \n",
    "                        margins=True).reindex(['Elite', 'Mid', 'Bottom', 'All'])\n",
    "agreement = agreement[['Elite', 'Mid', 'Bottom', 'All']]\n",
    "print(f\"\\nTier Agreement (rows=Simple, cols=Network):\")\n",
    "print(agreement)\n",
    "\n",
    "# Disagreements\n",
    "disagreements = df_teams[df_teams['simple_tier'] != df_teams['network_tier']]\n",
    "print(f\"\\nTeams with different tier classification ({len(disagreements)}):\\n\")\n",
    "print(disagreements[['team', 'simple_win_pct', 'network_rating', 'simple_sos', 'network_sos', \n",
    "                     'simple_tier', 'network_tier']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-opp-header",
   "metadata": {},
   "source": [
    "## Phase 6: Multi-Hop Common Opponent Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multi-hop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_opponent_paths(G, team_a, team_b, max_hops=2):\n",
    "    \"\"\"\n",
    "    Find all paths through common opponents between two teams.\n",
    "    \n",
    "    Returns paths of form:\n",
    "    - 1-hop: team_a beat C, team_b lost to C (or vice versa)\n",
    "    - 2-hop: team_a beat C who beat D who team_b lost to\n",
    "    \"\"\"\n",
    "    # Convert to undirected for path finding\n",
    "    G_undirected = G.to_undirected()\n",
    "    \n",
    "    if team_a not in G or team_b not in G:\n",
    "        return []\n",
    "    \n",
    "    paths = []\n",
    "    try:\n",
    "        for path in nx.all_simple_paths(G_undirected, team_a, team_b, cutoff=max_hops + 1):\n",
    "            if len(path) > 2:  # At least one intermediate team\n",
    "                paths.append(path)\n",
    "    except nx.NetworkXNoPath:\n",
    "        pass\n",
    "    \n",
    "    return paths\n",
    "\n",
    "def evaluate_matchup_via_paths(G, team_a, team_b, ratings, max_hops=2):\n",
    "    \"\"\"\n",
    "    Evaluate two teams' relative strength through common opponent paths.\n",
    "    \n",
    "    For each path, compare how each team performed against intermediates.\n",
    "    Weight by intermediate team's strength (better opponents = more weight).\n",
    "    \"\"\"\n",
    "    paths = find_common_opponent_paths(G, team_a, team_b, max_hops)\n",
    "    \n",
    "    if not paths:\n",
    "        return None, 0, []\n",
    "    \n",
    "    a_total_score = 0\n",
    "    b_total_score = 0\n",
    "    total_weight = 0\n",
    "    path_details = []\n",
    "    \n",
    "    for path in paths:\n",
    "        intermediates = path[1:-1]\n",
    "        \n",
    "        a_path_score = 0\n",
    "        b_path_score = 0\n",
    "        path_weight = 0\n",
    "        \n",
    "        for intermediate in intermediates:\n",
    "            int_rating = ratings.get(intermediate, 0.5)\n",
    "            \n",
    "            # Team A's performance vs intermediate\n",
    "            if G.has_edge(team_a, intermediate):  # A beat intermediate\n",
    "                margin = G[team_a][intermediate].get('avg_margin', 0)\n",
    "                a_path_score += margin * int_rating\n",
    "            elif G.has_edge(intermediate, team_a):  # A lost to intermediate\n",
    "                margin = G[intermediate][team_a].get('avg_margin', 0)\n",
    "                a_path_score -= margin * int_rating\n",
    "            \n",
    "            # Team B's performance vs intermediate\n",
    "            if G.has_edge(team_b, intermediate):  # B beat intermediate\n",
    "                margin = G[team_b][intermediate].get('avg_margin', 0)\n",
    "                b_path_score += margin * int_rating\n",
    "            elif G.has_edge(intermediate, team_b):  # B lost to intermediate\n",
    "                margin = G[intermediate][team_b].get('avg_margin', 0)\n",
    "                b_path_score -= margin * int_rating\n",
    "            \n",
    "            path_weight += int_rating\n",
    "        \n",
    "        if path_weight > 0:\n",
    "            a_total_score += a_path_score\n",
    "            b_total_score += b_path_score\n",
    "            total_weight += path_weight\n",
    "            \n",
    "            path_details.append({\n",
    "                'path': ' -> '.join(path),\n",
    "                'a_score': a_path_score / path_weight,\n",
    "                'b_score': b_path_score / path_weight\n",
    "            })\n",
    "    \n",
    "    if total_weight == 0:\n",
    "        return None, 0, []\n",
    "    \n",
    "    # Positive = team_a favored, negative = team_b favored\n",
    "    edge = (a_total_score - b_total_score) / total_weight\n",
    "    \n",
    "    return edge, len(paths), path_details\n",
    "\n",
    "# Example: Compare top team vs bottom team\n",
    "top_team = df_teams.iloc[0]['team']\n",
    "bottom_team = df_teams.iloc[-1]['team']\n",
    "\n",
    "edge, num_paths, details = evaluate_matchup_via_paths(G, top_team, bottom_team, network_ratings, CONFIG['max_hops'])\n",
    "\n",
    "print(f\"Matchup Analysis: {top_team} vs {bottom_team}\")\n",
    "print(f\"Paths found: {num_paths}\")\n",
    "print(f\"Common opponent edge: {edge:.2f} ({'favors ' + top_team if edge > 0 else 'favors ' + bottom_team})\")\n",
    "print(f\"\\nPath details:\")\n",
    "for d in details[:5]:  # Show first 5 paths\n",
    "    print(f\"  {d['path']}\")\n",
    "    print(f\"    {top_team} score: {d['a_score']:.2f}, {bottom_team} score: {d['b_score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coverage-header",
   "metadata": {},
   "source": [
    "## Phase 7: Coverage Analysis by Network Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coverage-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate handicap coverage by network tier\n",
    "handicaps = [0, 5, 9, 11, 13]\n",
    "\n",
    "# Add tier info to games\n",
    "tier_map = df_teams.set_index('team')[['simple_tier', 'network_tier']].to_dict()\n",
    "\n",
    "for h in handicaps:\n",
    "    df[f'home_covers_{h}pt'] = (df['spread_result_difference'] + h) >= 0\n",
    "    df[f'away_covers_{h}pt'] = df['spread_result_difference'] <= h\n",
    "\n",
    "# Analyze coverage by tier\n",
    "results = []\n",
    "\n",
    "for h in handicaps:\n",
    "    for tier_type in ['simple_tier', 'network_tier']:\n",
    "        for tier in ['Elite', 'Mid', 'Bottom']:\n",
    "            tier_teams = df_teams[df_teams[tier_type] == tier]['team'].tolist()\n",
    "            \n",
    "            total_games = 0\n",
    "            total_covers = 0\n",
    "            \n",
    "            for team in tier_teams:\n",
    "                # Home games\n",
    "                hg = df[df['home_team'] == team]\n",
    "                total_games += len(hg)\n",
    "                total_covers += hg[f'home_covers_{h}pt'].sum()\n",
    "                \n",
    "                # Away games\n",
    "                ag = df[df['away_team'] == team]\n",
    "                total_games += len(ag)\n",
    "                total_covers += ag[f'away_covers_{h}pt'].sum()\n",
    "            \n",
    "            results.append({\n",
    "                'handicap': h,\n",
    "                'tier_type': tier_type,\n",
    "                'tier': tier,\n",
    "                'games': total_games,\n",
    "                'covers': total_covers,\n",
    "                'cover_pct': total_covers / total_games if total_games > 0 else 0\n",
    "            })\n",
    "\n",
    "df_coverage = pd.DataFrame(results)\n",
    "\n",
    "# Compare simple vs network tier coverage\n",
    "print(\"Coverage % by Tier Type and Handicap:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for tier_type in ['simple_tier', 'network_tier']:\n",
    "    print(f\"\\n{tier_type.replace('_', ' ').title()}:\")\n",
    "    pivot = df_coverage[df_coverage['tier_type'] == tier_type].pivot(\n",
    "        index='handicap', columns='tier', values='cover_pct'\n",
    "    )[['Elite', 'Mid', 'Bottom']]\n",
    "    print((pivot * 100).round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Elite tier coverage: Simple vs Network\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "colors = {'Elite': '#2ecc71', 'Mid': '#f39c12', 'Bottom': '#e74c3c'}\n",
    "\n",
    "for idx, tier_type in enumerate(['simple_tier', 'network_tier']):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for tier in ['Elite', 'Mid', 'Bottom']:\n",
    "        data = df_coverage[(df_coverage['tier_type'] == tier_type) & (df_coverage['tier'] == tier)]\n",
    "        ax.plot(data['handicap'], data['cover_pct'] * 100, \n",
    "                marker='o', label=tier, color=colors[tier], linewidth=2)\n",
    "    \n",
    "    ax.axhline(y=50, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Handicap Points')\n",
    "    ax.set_ylabel('Coverage %')\n",
    "    ax.set_title(f'{tier_type.replace(\"_\", \" \").title()}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('NFL: Coverage by Tier Classification Method', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"NFL NETWORK STRENGTH ANALYSIS: SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n1. DATA\")\n",
    "print(f\"   - Games analyzed: {len(df)}\")\n",
    "print(f\"   - Teams: {len(all_teams)}\")\n",
    "print(f\"   - Network edges: {G.number_of_edges()}\")\n",
    "\n",
    "print(f\"\\n2. NETWORK RATING VALIDATION\")\n",
    "print(f\"   - Correlation with Win%: {corr_win_pct:.3f}\")\n",
    "print(f\"   - Correlation with Point Diff: {corr_point_diff:.3f}\")\n",
    "print(f\"   - Network SOS vs Simple SOS: {corr_sos:.3f}\")\n",
    "\n",
    "print(f\"\\n3. TIER CLASSIFICATION COMPARISON\")\n",
    "tier_agreement = (df_teams['simple_tier'] == df_teams['network_tier']).mean() * 100\n",
    "print(f\"   - Agreement rate: {tier_agreement:.1f}%\")\n",
    "print(f\"   - Disagreements: {len(disagreements)} teams\")\n",
    "\n",
    "print(f\"\\n4. COVERAGE BY TIER (11pt handicap)\")\n",
    "for tier_type in ['simple_tier', 'network_tier']:\n",
    "    print(f\"   {tier_type.replace('_', ' ').title()}:\")\n",
    "    for tier in ['Elite', 'Mid', 'Bottom']:\n",
    "        pct = df_coverage[(df_coverage['tier_type'] == tier_type) & \n",
    "                         (df_coverage['tier'] == tier) &\n",
    "                         (df_coverage['handicap'] == 11)]['cover_pct'].values[0] * 100\n",
    "        print(f\"      {tier}: {pct:.1f}%\")\n",
    "\n",
    "print(f\"\\n5. RECOMMENDATIONS\")\n",
    "if corr_win_pct > 0.9:\n",
    "    print(\"   - Network rating highly correlated with Win% - may not add much value\")\n",
    "else:\n",
    "    print(\"   - Network rating captures different signal than simple Win%\")\n",
    "    \n",
    "if tier_agreement < 80:\n",
    "    print(\"   - Significant tier differences - network rating may identify mispriced teams\")\n",
    "\n",
    "# Check if network tier predicts coverage better\n",
    "elite_simple_11 = df_coverage[(df_coverage['tier_type'] == 'simple_tier') & \n",
    "                              (df_coverage['tier'] == 'Elite') & \n",
    "                              (df_coverage['handicap'] == 11)]['cover_pct'].values[0]\n",
    "elite_network_11 = df_coverage[(df_coverage['tier_type'] == 'network_tier') & \n",
    "                               (df_coverage['tier'] == 'Elite') & \n",
    "                               (df_coverage['handicap'] == 11)]['cover_pct'].values[0]\n",
    "\n",
    "if elite_network_11 > elite_simple_11:\n",
    "    print(f\"   - Network Elite teams cover better than Simple Elite ({elite_network_11*100:.1f}% vs {elite_simple_11*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"   - Simple Elite teams cover slightly better ({elite_simple_11*100:.1f}% vs {elite_network_11*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-ratings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export team data with all metrics\n",
    "export_df = df_teams[['team', 'games', 'wins', 'simple_win_pct', 'network_rating', \n",
    "                      'point_diff_avg', 'simple_sos', 'network_sos', \n",
    "                      'simple_tier', 'network_tier']].copy()\n",
    "\n",
    "export_file = Path().resolve().parent / 'data' / 'results' / 'nfl_network_ratings.csv'\n",
    "export_df.to_csv(export_file, index=False)\n",
    "print(f\"Exported team ratings to: {export_file}\")\n",
    "\n",
    "export_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}