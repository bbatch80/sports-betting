{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# NCAAM Handicap Spread Coverage Network Rating\n",
    "\n",
    "## Objective\n",
    "Build network-based strength ratings using **handicap-adjusted spread coverage**.\n",
    "This applies an 11-point cushion from each team's perspective to identify:\n",
    "- **Cushion-Dependent Teams**: Need the handicap to cover\n",
    "- **Cushion-Proof Teams**: Cover comfortably regardless of handicap\n",
    "\n",
    "## Key Concept\n",
    "- Home covers with handicap if: `spread_result_diff >= -11`\n",
    "- Away covers with handicap if: `spread_result_diff <= 11`\n",
    "- Games within ±11 points → both teams \"cover with handicap\"\n",
    "- Network edge goes to team with larger handicap-adjusted margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# NCAAM Handicap Spread Config\n",
    "CONFIG = {\n",
    "    'sport': 'NCAAM',\n",
    "    'handicap': 11,          # Point cushion applied to each team\n",
    "    'margin_cap': 12,        # College variance slightly higher\n",
    "    'recency_decay': 0.92,\n",
    "    'learning_rate': 0.08,\n",
    "    'iterations': 100,\n",
    "    'tolerance': 0.001\n",
    "}\n",
    "\n",
    "print(f\"Handicap Spread Config: {CONFIG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Phase 1: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NCAAM data\n",
    "data_file = Path().resolve().parent / 'data' / 'results' / 'ncaam_season_results.xlsx'\n",
    "df = pd.read_excel(data_file)\n",
    "\n",
    "print(f\"Loaded {len(df)} NCAAM games\")\n",
    "print(f\"Date range: {df['game_date'].min().date()} to {df['game_date'].max().date()}\")\n",
    "\n",
    "# Filter to games with spread data\n",
    "df_spread = df[df['spread_result_difference'].notna()].copy()\n",
    "print(f\"\\nGames with spread data: {len(df_spread)}\")\n",
    "\n",
    "# Get all teams\n",
    "all_teams = set(df_spread['home_team'].unique()) | set(df_spread['away_team'].unique())\n",
    "print(f\"Total teams: {len(all_teams)}\")\n",
    "\n",
    "df_spread.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handicap-header",
   "metadata": {},
   "source": [
    "## Phase 2: Handicap-Adjusted Cover Determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handicap-calc",
   "metadata": {},
   "outputs": [],
   "source": [
    "handicap = CONFIG['handicap']\n",
    "\n",
    "# Calculate handicap-adjusted margins from each team's perspective\n",
    "df_spread['home_margin_handicap'] = df_spread['spread_result_difference'] + handicap\n",
    "df_spread['away_margin_handicap'] = handicap - df_spread['spread_result_difference']\n",
    "\n",
    "# Determine if each team covers with the handicap\n",
    "df_spread['home_covers_handicap'] = df_spread['spread_result_difference'] >= -handicap\n",
    "df_spread['away_covers_handicap'] = df_spread['spread_result_difference'] <= handicap\n",
    "\n",
    "# For network: cover_team is the one with larger handicap-adjusted margin\n",
    "df_spread['cover_team'] = np.where(\n",
    "    df_spread['home_margin_handicap'] >= df_spread['away_margin_handicap'],\n",
    "    df_spread['home_team'],\n",
    "    df_spread['away_team']\n",
    ")\n",
    "df_spread['fail_team'] = np.where(\n",
    "    df_spread['home_margin_handicap'] >= df_spread['away_margin_handicap'],\n",
    "    df_spread['away_team'],\n",
    "    df_spread['home_team']\n",
    ")\n",
    "df_spread['cover_margin'] = np.maximum(\n",
    "    df_spread['home_margin_handicap'],\n",
    "    df_spread['away_margin_handicap']\n",
    ")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"Handicap Analysis ({handicap}pt cushion):\")\n",
    "print(f\"  Games where BOTH teams cover with handicap: {(df_spread['home_covers_handicap'] & df_spread['away_covers_handicap']).sum()}\")\n",
    "print(f\"  Games where only home covers: {(df_spread['home_covers_handicap'] & ~df_spread['away_covers_handicap']).sum()}\")\n",
    "print(f\"  Games where only away covers: {(~df_spread['home_covers_handicap'] & df_spread['away_covers_handicap']).sum()}\")\n",
    "print(f\"  Games where neither covers: {(~df_spread['home_covers_handicap'] & ~df_spread['away_covers_handicap']).sum()}\")\n",
    "\n",
    "df_spread[['game_date', 'home_team', 'away_team', 'spread_result_difference', \n",
    "           'home_margin_handicap', 'away_margin_handicap', 'cover_team', 'cover_margin']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-handicap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize handicap coverage distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Original spread result distribution with handicap thresholds\n",
    "ax = axes[0]\n",
    "ax.hist(df_spread['spread_result_difference'], bins=40, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(x=0, color='blue', linestyle='-', linewidth=2, label='0pt (original threshold)')\n",
    "ax.axvline(x=-handicap, color='green', linestyle='--', linewidth=2, label=f'-{handicap}pt (home handicap)')\n",
    "ax.axvline(x=handicap, color='red', linestyle='--', linewidth=2, label=f'+{handicap}pt (away handicap)')\n",
    "ax.axvspan(-handicap, handicap, alpha=0.2, color='yellow', label='Both cover zone')\n",
    "ax.set_xlabel('Spread Result Difference')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title(f'Spread Results with {handicap}pt Handicap Zones')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# Cover margin distribution (handicap-adjusted)\n",
    "ax = axes[1]\n",
    "ax.hist(df_spread['cover_margin'], bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "ax.axvline(x=CONFIG['margin_cap'], color='r', linestyle='--', label=f\"Margin Cap ({CONFIG['margin_cap']}pts)\")\n",
    "ax.set_xlabel('Handicap-Adjusted Cover Margin')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Cover Margins (with handicap)')\n",
    "ax.legend()\n",
    "\n",
    "# Compare: original vs handicap cover rates\n",
    "ax = axes[2]\n",
    "original_home_cover = (df_spread['spread_result_difference'] >= 0).mean() * 100\n",
    "original_away_cover = (df_spread['spread_result_difference'] < 0).mean() * 100\n",
    "handicap_home_cover = df_spread['home_covers_handicap'].mean() * 100\n",
    "handicap_away_cover = df_spread['away_covers_handicap'].mean() * 100\n",
    "\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, [original_home_cover, original_away_cover], width, label='0pt (Original)', color='#3498db')\n",
    "ax.bar(x + width/2, [handicap_home_cover, handicap_away_cover], width, label=f'{handicap}pt Handicap', color='#2ecc71')\n",
    "ax.axhline(y=50, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Home', 'Away'])\n",
    "ax.set_ylabel('Cover Rate (%)')\n",
    "ax.set_title('Cover Rates: Original vs Handicap')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOriginal Cover Rates: Home {original_home_cover:.1f}%, Away {original_away_cover:.1f}%\")\n",
    "print(f\"Handicap Cover Rates: Home {handicap_home_cover:.1f}%, Away {handicap_away_cover:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "network-header",
   "metadata": {},
   "source": [
    "## Phase 3: Build Handicap Network & Compute Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_handicap_network(games_df, recency_decay=0.92):\n",
    "    \"\"\"\n",
    "    Build weighted directed graph from handicap-adjusted spread coverage.\n",
    "    Edge: cover_team -> fail_team (based on larger handicap margin)\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    for team in all_teams:\n",
    "        G.add_node(team)\n",
    "    \n",
    "    games_sorted = games_df.sort_values('game_date')\n",
    "    max_date = games_sorted['game_date'].max()\n",
    "    \n",
    "    edge_data = {}\n",
    "    \n",
    "    for _, game in games_sorted.iterrows():\n",
    "        cover_team = game['cover_team']\n",
    "        fail_team = game['fail_team']\n",
    "        cover_margin = game['cover_margin']\n",
    "        \n",
    "        days_ago = (max_date - game['game_date']).days\n",
    "        recency_weight = recency_decay ** (days_ago / 7)\n",
    "        \n",
    "        key = (cover_team, fail_team)\n",
    "        if key not in edge_data:\n",
    "            edge_data[key] = {\n",
    "                'games': 0,\n",
    "                'total_margin': 0,\n",
    "                'weighted_margin': 0,\n",
    "                'total_weight': 0\n",
    "            }\n",
    "        \n",
    "        edge_data[key]['games'] += 1\n",
    "        edge_data[key]['total_margin'] += cover_margin\n",
    "        edge_data[key]['weighted_margin'] += cover_margin * recency_weight\n",
    "        edge_data[key]['total_weight'] += recency_weight\n",
    "    \n",
    "    for (cover_team, fail_team), data in edge_data.items():\n",
    "        G.add_edge(cover_team, fail_team,\n",
    "                   games=data['games'],\n",
    "                   avg_margin=data['total_margin'] / data['games'],\n",
    "                   weighted_margin=data['weighted_margin'] / data['total_weight'])\n",
    "    \n",
    "    return G\n",
    "\n",
    "G_handicap = build_handicap_network(df_spread, CONFIG['recency_decay'])\n",
    "\n",
    "print(f\"Handicap Network Summary:\")\n",
    "print(f\"  Nodes: {G_handicap.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G_handicap.number_of_edges()}\")\n",
    "print(f\"  Density: {nx.density(G_handicap):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-ratings",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_handicap_rating(games_df, max_iterations=100, tolerance=0.001, \n",
    "                            margin_cap=12, learning_rate=0.08):\n",
    "    \"\"\"\n",
    "    Compute network-propagated handicap spread coverage ratings.\n",
    "    \"\"\"\n",
    "    teams = set(games_df['home_team']) | set(games_df['away_team'])\n",
    "    ratings = {team: 0.5 for team in teams}\n",
    "    history = []\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        new_ratings = ratings.copy()\n",
    "        \n",
    "        for _, game in games_df.iterrows():\n",
    "            cover_team = game['cover_team']\n",
    "            fail_team = game['fail_team']\n",
    "            cover_margin = min(game['cover_margin'], margin_cap)\n",
    "            \n",
    "            total = ratings[cover_team] + ratings[fail_team]\n",
    "            expected = ratings[cover_team] / total if total > 0 else 0.5\n",
    "            surprise = 1 - expected\n",
    "            adjustment = surprise * (cover_margin / margin_cap) * learning_rate\n",
    "            \n",
    "            new_ratings[cover_team] += adjustment\n",
    "            new_ratings[fail_team] -= adjustment\n",
    "        \n",
    "        min_r, max_r = min(new_ratings.values()), max(new_ratings.values())\n",
    "        if max_r > min_r:\n",
    "            new_ratings = {t: (r - min_r) / (max_r - min_r) for t, r in new_ratings.items()}\n",
    "        \n",
    "        max_change = max(abs(new_ratings[t] - ratings[t]) for t in teams)\n",
    "        history.append(max_change)\n",
    "        \n",
    "        if max_change < tolerance:\n",
    "            print(f\"Converged at iteration {iteration + 1}\")\n",
    "            break\n",
    "        \n",
    "        ratings = new_ratings\n",
    "    \n",
    "    return ratings, history\n",
    "\n",
    "handicap_ratings, convergence = compute_handicap_rating(\n",
    "    df_spread,\n",
    "    max_iterations=CONFIG['iterations'],\n",
    "    tolerance=CONFIG['tolerance'],\n",
    "    margin_cap=CONFIG['margin_cap'],\n",
    "    learning_rate=CONFIG['learning_rate']\n",
    ")\n",
    "\n",
    "# Display top teams\n",
    "handicap_df = pd.DataFrame([\n",
    "    {'team': team, 'handicap_rating': rating}\n",
    "    for team, rating in handicap_ratings.items()\n",
    "]).sort_values('handicap_rating', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Teams by Handicap Rating:\")\n",
    "print(handicap_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-header",
   "metadata": {},
   "source": [
    "## Phase 4: Compare to Non-Handicap (0pt) Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute original (0pt) spread coverage rating for comparison\n",
    "df_original = df_spread.copy()\n",
    "df_original['cover_team'] = np.where(\n",
    "    df_original['spread_result_difference'] >= 0,\n",
    "    df_original['home_team'],\n",
    "    df_original['away_team']\n",
    ")\n",
    "df_original['fail_team'] = np.where(\n",
    "    df_original['spread_result_difference'] >= 0,\n",
    "    df_original['away_team'],\n",
    "    df_original['home_team']\n",
    ")\n",
    "df_original['cover_margin'] = df_original['spread_result_difference'].abs()\n",
    "\n",
    "original_ratings, _ = compute_handicap_rating(\n",
    "    df_original,\n",
    "    max_iterations=CONFIG['iterations'],\n",
    "    tolerance=CONFIG['tolerance'],\n",
    "    margin_cap=CONFIG['margin_cap'],\n",
    "    learning_rate=CONFIG['learning_rate']\n",
    ")\n",
    "\n",
    "print(\"Original (0pt) spread ratings computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build comparison dataframe\n",
    "team_stats = []\n",
    "\n",
    "for team in all_teams:\n",
    "    home_games = df_spread[df_spread['home_team'] == team]\n",
    "    away_games = df_spread[df_spread['away_team'] == team]\n",
    "    total_games = len(home_games) + len(away_games)\n",
    "    \n",
    "    # Original cover stats\n",
    "    orig_home_covers = (home_games['spread_result_difference'] >= 0).sum()\n",
    "    orig_away_covers = (away_games['spread_result_difference'] < 0).sum()\n",
    "    original_covers = orig_home_covers + orig_away_covers\n",
    "    \n",
    "    # Handicap cover stats\n",
    "    hcap_home_covers = home_games['home_covers_handicap'].sum()\n",
    "    hcap_away_covers = away_games['away_covers_handicap'].sum()\n",
    "    handicap_covers = hcap_home_covers + hcap_away_covers\n",
    "    \n",
    "    team_stats.append({\n",
    "        'team': team,\n",
    "        'games': total_games,\n",
    "        'original_covers': original_covers,\n",
    "        'original_cover_pct': original_covers / total_games if total_games > 0 else 0,\n",
    "        'handicap_covers': handicap_covers,\n",
    "        'handicap_cover_pct': handicap_covers / total_games if total_games > 0 else 0,\n",
    "        'original_rating': original_ratings.get(team, 0.5),\n",
    "        'handicap_rating': handicap_ratings.get(team, 0.5)\n",
    "    })\n",
    "\n",
    "df_compare = pd.DataFrame(team_stats)\n",
    "\n",
    "# Calculate key metrics\n",
    "df_compare['handicap_delta'] = df_compare['handicap_rating'] - df_compare['original_rating']\n",
    "df_compare['cover_pct_gain'] = df_compare['handicap_cover_pct'] - df_compare['original_cover_pct']\n",
    "\n",
    "df_compare = df_compare.sort_values('handicap_delta', ascending=False)\n",
    "\n",
    "print(f\"Rating Comparison: Original (0pt) vs Handicap ({handicap}pt)\")\n",
    "print(\"=\"*90)\n",
    "print(df_compare[['team', 'original_cover_pct', 'handicap_cover_pct', 'cover_pct_gain',\n",
    "                  'original_rating', 'handicap_rating', 'handicap_delta']].head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Scatter: Original vs Handicap Rating\n",
    "ax = axes[0]\n",
    "scatter = ax.scatter(df_compare['original_rating'], df_compare['handicap_rating'],\n",
    "                     c=df_compare['handicap_delta'], cmap='RdYlGn', s=50, alpha=0.6)\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Equal ratings')\n",
    "ax.set_xlabel('Original Rating (0pt)')\n",
    "ax.set_ylabel(f'Handicap Rating ({handicap}pt)')\n",
    "ax.set_title('Original vs Handicap Rating\\n(Color = Handicap Delta)')\n",
    "fig.colorbar(scatter, ax=ax, label='Handicap Delta')\n",
    "\n",
    "# Histogram of Handicap Deltas\n",
    "ax = axes[1]\n",
    "ax.hist(df_compare['handicap_delta'], bins=30, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "ax.axvline(x=df_compare['handicap_delta'].mean(), color='red', linestyle='--', \n",
    "           label=f\"Mean: {df_compare['handicap_delta'].mean():.3f}\")\n",
    "ax.set_xlabel('Handicap Delta')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Handicap Deltas')\n",
    "ax.legend()\n",
    "\n",
    "# Top/Bottom teams by delta\n",
    "ax = axes[2]\n",
    "top_bottom = pd.concat([df_compare.head(10), df_compare.tail(10)])\n",
    "colors = ['#2ecc71' if d > 0 else '#e74c3c' for d in top_bottom['handicap_delta']]\n",
    "ax.barh(top_bottom['team'], top_bottom['handicap_delta'], color=colors)\n",
    "ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "ax.set_xlabel('Handicap Delta')\n",
    "ax.set_title(f'Top/Bottom 10 Teams by Handicap Delta')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classify-header",
   "metadata": {},
   "source": [
    "## Phase 5: Classify Teams (Cushion-Dependent vs Cushion-Proof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classify-teams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify teams based on handicap delta (use percentile for NCAAM due to many teams)\n",
    "top_pct = df_compare['handicap_delta'].quantile(0.9)\n",
    "bottom_pct = df_compare['handicap_delta'].quantile(0.1)\n",
    "\n",
    "cushion_dependent = df_compare[df_compare['handicap_delta'] >= top_pct].sort_values('handicap_delta', ascending=False)\n",
    "cushion_proof = df_compare[df_compare['handicap_delta'] <= bottom_pct].sort_values('handicap_delta')\n",
    "neutral = df_compare[(df_compare['handicap_delta'] > bottom_pct) & \n",
    "                     (df_compare['handicap_delta'] < top_pct)]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"TEAM CLASSIFICATION ({handicap}pt Handicap Analysis)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n\\U0001F7E1 CUSHION-DEPENDENT TEAMS (Top 10% by delta, {len(cushion_dependent)} teams)\")\n",
    "print(f\"These teams improve significantly with the {handicap}pt cushion.\")\n",
    "print(\"They may be underperforming against the spread but competitive in games.\")\n",
    "print(\"-\"*80)\n",
    "if len(cushion_dependent) > 0:\n",
    "    print(cushion_dependent[['team', 'games', 'original_cover_pct', 'handicap_cover_pct', \n",
    "                             'original_rating', 'handicap_rating', 'handicap_delta']].head(15).to_string(index=False))\n",
    "\n",
    "print(f\"\\n\\U0001F7E2 CUSHION-PROOF TEAMS (Bottom 10% by delta, {len(cushion_proof)} teams)\")\n",
    "print(f\"These teams perform WORSE relative to others with the {handicap}pt cushion.\")\n",
    "print(\"They already cover convincingly - the cushion helps their opponents more.\")\n",
    "print(\"-\"*80)\n",
    "if len(cushion_proof) > 0:\n",
    "    print(cushion_proof[['team', 'games', 'original_cover_pct', 'handicap_cover_pct', \n",
    "                         'original_rating', 'handicap_rating', 'handicap_delta']].head(15).to_string(index=False))\n",
    "\n",
    "print(f\"\\n\\U00002B1C NEUTRAL TEAMS ({len(neutral)} teams)\")\n",
    "print(f\"These teams' relative rankings don't change much with the {handicap}pt cushion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "predictive-header",
   "metadata": {},
   "source": [
    "## Phase 6: Predictive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predictive-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for predictive testing\n",
    "df_sorted = df_spread.sort_values('game_date')\n",
    "split_idx = int(len(df_sorted) * 0.75)\n",
    "\n",
    "train_df = df_sorted.iloc[:split_idx].copy()\n",
    "test_df = df_sorted.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"Training: {len(train_df)} games\")\n",
    "print(f\"Testing: {len(test_df)} games\")\n",
    "\n",
    "# Compute handicap ratings on training data\n",
    "train_df['cover_team'] = np.where(\n",
    "    train_df['home_margin_handicap'] >= train_df['away_margin_handicap'],\n",
    "    train_df['home_team'],\n",
    "    train_df['away_team']\n",
    ")\n",
    "train_df['fail_team'] = np.where(\n",
    "    train_df['home_margin_handicap'] >= train_df['away_margin_handicap'],\n",
    "    train_df['away_team'],\n",
    "    train_df['home_team']\n",
    ")\n",
    "train_df['cover_margin'] = np.maximum(train_df['home_margin_handicap'], train_df['away_margin_handicap'])\n",
    "\n",
    "train_ratings, _ = compute_handicap_rating(train_df, margin_cap=CONFIG['margin_cap'])\n",
    "\n",
    "# Calculate test period cover rates (with handicap)\n",
    "# Only include teams with at least 3 games in test period\n",
    "test_cover_rates = {}\n",
    "for team in all_teams:\n",
    "    home_test = test_df[test_df['home_team'] == team]\n",
    "    away_test = test_df[test_df['away_team'] == team]\n",
    "    \n",
    "    total = len(home_test) + len(away_test)\n",
    "    if total >= 3:\n",
    "        covers = home_test['home_covers_handicap'].sum() + away_test['away_covers_handicap'].sum()\n",
    "        test_cover_rates[team] = covers / total\n",
    "\n",
    "# Correlation\n",
    "pred_df = pd.DataFrame([\n",
    "    {'team': t, 'train_rating': train_ratings.get(t, 0.5), 'test_cover': test_cover_rates.get(t, np.nan)}\n",
    "    for t in all_teams if t in test_cover_rates and t in train_ratings\n",
    "])\n",
    "\n",
    "corr = pred_df['train_rating'].corr(pred_df['test_cover'])\n",
    "print(f\"\\nTeams with 3+ test games: {len(pred_df)}\")\n",
    "print(f\"Predictive Correlation (Training Handicap Rating vs Test Cover Rate): {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-predictive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictive power\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.scatter(pred_df['train_rating'], pred_df['test_cover'], alpha=0.5, s=40)\n",
    "ax.set_xlabel('Training Handicap Rating')\n",
    "ax.set_ylabel('Test Period Handicap Cover Rate')\n",
    "ax.set_title(f'Predictive Power ({handicap}pt Handicap)\\nCorrelation: {corr:.3f}')\n",
    "\n",
    "z = np.polyfit(pred_df['train_rating'], pred_df['test_cover'], 1)\n",
    "p = np.poly1d(z)\n",
    "ax.plot([0, 1], [p(0), p(1)], 'r--', label=f'Trend')\n",
    "ax.legend()\n",
    "\n",
    "# Tier analysis\n",
    "ax = axes[1]\n",
    "pred_df['tier'] = pd.qcut(pred_df['train_rating'], q=4, labels=['Bottom 25%', 'Lower Mid', 'Upper Mid', 'Top 25%'])\n",
    "tier_cover = pred_df.groupby('tier')['test_cover'].mean()\n",
    "\n",
    "colors = ['#e74c3c', '#f39c12', '#3498db', '#2ecc71']\n",
    "bars = ax.bar(tier_cover.index, tier_cover.values * 100, color=colors)\n",
    "ax.axhline(y=50, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_ylabel('Test Period Handicap Cover Rate (%)')\n",
    "ax.set_title(f'Future Cover Rate by Training Tier ({handicap}pt Handicap)')\n",
    "ax.tick_params(axis='x', rotation=15)\n",
    "\n",
    "for bar, val in zip(bars, tier_cover.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f'{val*100:.1f}%', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(f\"NCAAM {handicap}PT HANDICAP SPREAD NETWORK ANALYSIS: SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n1. DATA\")\n",
    "print(f\"   - Games analyzed: {len(df_spread)}\")\n",
    "print(f\"   - Teams: {len(all_teams)}\")\n",
    "print(f\"   - Handicap: {handicap} points\")\n",
    "\n",
    "print(f\"\\n2. COVER RATE CHANGES\")\n",
    "print(f\"   - Original home cover rate: {original_home_cover:.1f}%\")\n",
    "print(f\"   - Handicap home cover rate: {handicap_home_cover:.1f}%\")\n",
    "print(f\"   - Games where both cover with handicap: {(df_spread['home_covers_handicap'] & df_spread['away_covers_handicap']).sum()}\")\n",
    "\n",
    "rating_corr = df_compare['original_rating'].corr(df_compare['handicap_rating'])\n",
    "print(f\"\\n3. RATING CORRELATION\")\n",
    "print(f\"   - Original vs Handicap rating correlation: {rating_corr:.3f}\")\n",
    "print(f\"   - Mean handicap delta: {df_compare['handicap_delta'].mean():.4f}\")\n",
    "print(f\"   - Std handicap delta: {df_compare['handicap_delta'].std():.4f}\")\n",
    "\n",
    "print(f\"\\n4. TEAM CLASSIFICATION\")\n",
    "print(f\"   - Cushion-Dependent (top 10%): {len(cushion_dependent)} teams\")\n",
    "print(f\"   - Cushion-Proof (bottom 10%): {len(cushion_proof)} teams\")\n",
    "print(f\"   - Neutral: {len(neutral)} teams\")\n",
    "\n",
    "if len(cushion_dependent) > 0:\n",
    "    top_dependent = cushion_dependent.iloc[0]\n",
    "    print(f\"   - Most cushion-dependent: {top_dependent['team']} (delta: +{top_dependent['handicap_delta']:.3f})\")\n",
    "if len(cushion_proof) > 0:\n",
    "    top_proof = cushion_proof.iloc[0]\n",
    "    print(f\"   - Most cushion-proof: {top_proof['team']} (delta: {top_proof['handicap_delta']:.3f})\")\n",
    "\n",
    "print(f\"\\n5. PREDICTIVE POWER\")\n",
    "print(f\"   - Training-to-Test correlation: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "export_df = df_compare[['team', 'games', 'original_cover_pct', 'handicap_cover_pct',\n",
    "                        'original_rating', 'handicap_rating', 'handicap_delta']].copy()\n",
    "export_df = export_df.sort_values('handicap_rating', ascending=False)\n",
    "\n",
    "export_file = Path().resolve().parent / 'data' / 'results' / f'ncaam_handicap_{handicap}pt_ratings.csv'\n",
    "export_df.to_csv(export_file, index=False)\n",
    "print(f\"Exported to: {export_file}\")\n",
    "\n",
    "export_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
