{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# NBA Network-Based Team Strength Analysis\n",
    "\n",
    "## Objective\n",
    "Implement network-based strength propagation for team tier classification:\n",
    "- **Iterative Strength Ratings**: Massey/PageRank-style algorithm\n",
    "- **Network-Weighted SOS**: Strength of schedule using network ratings\n",
    "- **Multi-Hop Common Opponents**: 3-level transitive relationships\n",
    "\n",
    "## NBA-Specific Characteristics\n",
    "- 30 teams, 82-game regular season\n",
    "- Very dense graph (multiple matchups per pair)\n",
    "- High connectivity allows deeper path exploration\n",
    "- Parameters: `max_hops=3`, `recency_decay=0.95`, `margin_cap=15`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# NBA-specific config\n",
    "CONFIG = {\n",
    "    'sport': 'NBA',\n",
    "    'max_hops': 3,          # Dense graph allows deeper exploration\n",
    "    'recency_decay': 0.95,  # Season-long patterns matter\n",
    "    'margin_cap': 15,       # ~15 pts max impact\n",
    "    'iterations': 100,\n",
    "    'tolerance': 0.001\n",
    "}\n",
    "\n",
    "print(f\"Config: {CONFIG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Phase 1: Data Loading & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NBA data\n",
    "data_file = Path().resolve().parent / 'data' / 'results' / 'nba_season_results.xlsx'\n",
    "df = pd.read_excel(data_file)\n",
    "\n",
    "print(f\"Loaded {len(df)} NBA games\")\n",
    "print(f\"Date range: {df['game_date'].min().date()} to {df['game_date'].max().date()}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prep-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare game-level data with winner/loser/margin\n",
    "df['home_margin'] = df['home_score'] - df['away_score']\n",
    "df['winner'] = np.where(df['home_margin'] > 0, df['home_team'], \n",
    "                        np.where(df['home_margin'] < 0, df['away_team'], None))\n",
    "df['loser'] = np.where(df['home_margin'] > 0, df['away_team'], \n",
    "                       np.where(df['home_margin'] < 0, df['home_team'], None))\n",
    "df['margin'] = df['home_margin'].abs()\n",
    "\n",
    "# Drop ties (if any - rare in NBA due to OT)\n",
    "games_with_result = df[df['winner'].notna()].copy()\n",
    "print(f\"Games with decisive result: {len(games_with_result)} (dropped {len(df) - len(games_with_result)} ties)\")\n",
    "\n",
    "# Get all teams\n",
    "all_teams = set(df['home_team'].unique()) | set(df['away_team'].unique())\n",
    "print(f\"Total teams: {len(all_teams)}\")\n",
    "\n",
    "# Calculate avg games per team\n",
    "games_per_team = (len(df) * 2) / len(all_teams)\n",
    "print(f\"Avg games per team: {games_per_team:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graph-header",
   "metadata": {},
   "source": [
    "## Phase 2: Build Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_team_network(games_df, recency_decay=0.95):\n",
    "    \"\"\"\n",
    "    Build weighted directed graph from game results.\n",
    "    \n",
    "    For NBA: Multiple games between same teams common, aggregate results.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add all teams as nodes\n",
    "    for team in all_teams:\n",
    "        G.add_node(team)\n",
    "    \n",
    "    # Sort by date for recency weighting\n",
    "    games_sorted = games_df.sort_values('game_date')\n",
    "    max_date = games_sorted['game_date'].max()\n",
    "    \n",
    "    # Build edge data (aggregating multiple matchups)\n",
    "    edge_data = {}\n",
    "    \n",
    "    for _, game in games_sorted.iterrows():\n",
    "        winner, loser = game['winner'], game['loser']\n",
    "        margin = game['margin']\n",
    "        \n",
    "        # Calculate recency weight (exponential decay)\n",
    "        days_ago = (max_date - game['game_date']).days\n",
    "        recency_weight = recency_decay ** (days_ago / 7)  # Weekly decay\n",
    "        \n",
    "        key = (winner, loser)\n",
    "        if key not in edge_data:\n",
    "            edge_data[key] = {\n",
    "                'games': 0,\n",
    "                'total_margin': 0,\n",
    "                'weighted_margin': 0,\n",
    "                'total_weight': 0\n",
    "            }\n",
    "        \n",
    "        edge_data[key]['games'] += 1\n",
    "        edge_data[key]['total_margin'] += margin\n",
    "        edge_data[key]['weighted_margin'] += margin * recency_weight\n",
    "        edge_data[key]['total_weight'] += recency_weight\n",
    "    \n",
    "    # Add edges to graph\n",
    "    for (winner, loser), data in edge_data.items():\n",
    "        avg_margin = data['total_margin'] / data['games']\n",
    "        weighted_avg = data['weighted_margin'] / data['total_weight']\n",
    "        \n",
    "        G.add_edge(winner, loser, \n",
    "                   games=data['games'],\n",
    "                   avg_margin=avg_margin,\n",
    "                   weighted_margin=weighted_avg)\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Build the network\n",
    "G = build_team_network(games_with_result, CONFIG['recency_decay'])\n",
    "\n",
    "print(f\"Network Summary:\")\n",
    "print(f\"  Nodes (teams): {G.number_of_nodes()}\")\n",
    "print(f\"  Edges (winner->loser pairs): {G.number_of_edges()}\")\n",
    "print(f\"  Avg out-degree: {sum(dict(G.out_degree()).values()) / G.number_of_nodes():.1f}\")\n",
    "print(f\"  Density: {nx.density(G):.3f}\")\n",
    "\n",
    "# Show multi-game matchups\n",
    "multi_games = [(u, v, d['games']) for u, v, d in G.edges(data=True) if d['games'] > 1]\n",
    "print(f\"\\nMulti-game edges (same winner/loser): {len(multi_games)}\")\n",
    "if multi_games:\n",
    "    print(f\"  Example: {multi_games[0][0]} beat {multi_games[0][1]} {multi_games[0][2]} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-graph",
   "metadata": {},
   "outputs": [],
   "source": "# Visualize the network\nfig, ax = plt.subplots(figsize=(14, 14))\n\n# Calculate simple win percentage for coloring\nwin_counts = dict(G.out_degree())\nloss_counts = dict(G.in_degree())\nwin_pct = {team: win_counts.get(team, 0) / (win_counts.get(team, 0) + loss_counts.get(team, 0) + 0.001)\n           for team in all_teams}\n\n# Node colors based on win%\nnode_colors = [win_pct.get(node, 0.5) for node in G.nodes()]\n\n# Layout\npos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n\n# Draw\nnodes = nx.draw_networkx_nodes(G, pos, node_color=node_colors, cmap=plt.cm.RdYlGn,\n                               node_size=600, alpha=0.8, vmin=0.2, vmax=0.8, ax=ax)\nnx.draw_networkx_labels(G, pos, font_size=7, ax=ax)\nnx.draw_networkx_edges(G, pos, alpha=0.1, arrows=True,\n                       edge_color='gray', arrowsize=8, ax=ax)\n\nax.set_title(f'NBA Team Network (Edge: Winner -> Loser)\\nNode color: Win %', fontsize=14)\nfig.colorbar(nodes, ax=ax, label='Win %')\nax.axis('off')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "strength-header",
   "metadata": {},
   "source": [
    "## Phase 3: Iterative Strength Rating (Massey-Style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strength-algo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iterative_strength(games_df, max_iterations=100, tolerance=0.001, margin_cap=15):\n",
    "    \"\"\"\n",
    "    Compute network-propagated team strength ratings.\n",
    "    \n",
    "    For NBA: More games means more updates, so use smaller learning rate.\n",
    "    \"\"\"\n",
    "    teams = set(games_df['home_team']) | set(games_df['away_team'])\n",
    "    ratings = {team: 0.5 for team in teams}\n",
    "    games = games_df[games_df['winner'].notna()].copy()\n",
    "    \n",
    "    # Smaller learning rate for NBA (more games)\n",
    "    learning_rate = 0.05\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        new_ratings = ratings.copy()\n",
    "        \n",
    "        for _, game in games.iterrows():\n",
    "            winner = game['winner']\n",
    "            loser = game['loser']\n",
    "            margin = min(game['margin'], margin_cap)\n",
    "            \n",
    "            winner_rating = ratings[winner]\n",
    "            loser_rating = ratings[loser]\n",
    "            \n",
    "            total = winner_rating + loser_rating\n",
    "            expected = winner_rating / total if total > 0 else 0.5\n",
    "            \n",
    "            surprise = 1 - expected\n",
    "            adjustment = surprise * (margin / margin_cap) * learning_rate\n",
    "            \n",
    "            new_ratings[winner] += adjustment\n",
    "            new_ratings[loser] -= adjustment\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        min_r = min(new_ratings.values())\n",
    "        max_r = max(new_ratings.values())\n",
    "        if max_r > min_r:\n",
    "            new_ratings = {t: (r - min_r) / (max_r - min_r) for t, r in new_ratings.items()}\n",
    "        \n",
    "        max_change = max(abs(new_ratings[t] - ratings[t]) for t in teams)\n",
    "        history.append(max_change)\n",
    "        \n",
    "        if max_change < tolerance:\n",
    "            print(f\"Converged at iteration {iteration + 1}\")\n",
    "            break\n",
    "        \n",
    "        ratings = new_ratings\n",
    "    \n",
    "    return ratings, history\n",
    "\n",
    "# Compute ratings\n",
    "network_ratings, convergence_history = compute_iterative_strength(\n",
    "    df, \n",
    "    max_iterations=CONFIG['iterations'],\n",
    "    tolerance=CONFIG['tolerance'],\n",
    "    margin_cap=CONFIG['margin_cap']\n",
    ")\n",
    "\n",
    "# Display top teams\n",
    "ratings_df = pd.DataFrame([\n",
    "    {'team': team, 'network_rating': rating}\n",
    "    for team, rating in network_ratings.items()\n",
    "]).sort_values('network_rating', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Teams by Network Rating:\")\n",
    "print(ratings_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convergence\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(convergence_history)\n",
    "plt.axhline(y=CONFIG['tolerance'], color='r', linestyle='--', label=f\"Tolerance ({CONFIG['tolerance']})\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Max Rating Change')\n",
    "plt.title('NBA: Convergence of Iterative Strength Algorithm')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation-header",
   "metadata": {},
   "source": [
    "## Phase 4: Validate Ratings vs Simple Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calc-simple-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate simple team stats\n",
    "team_stats = []\n",
    "for team in all_teams:\n",
    "    home_games = df[df['home_team'] == team]\n",
    "    away_games = df[df['away_team'] == team]\n",
    "    \n",
    "    home_wins = (home_games['home_score'] > home_games['away_score']).sum()\n",
    "    away_wins = (away_games['away_score'] > away_games['home_score']).sum()\n",
    "    \n",
    "    home_diff = (home_games['home_score'] - home_games['away_score']).sum()\n",
    "    away_diff = (away_games['away_score'] - away_games['home_score']).sum()\n",
    "    \n",
    "    total_games = len(home_games) + len(away_games)\n",
    "    \n",
    "    opponents = list(home_games['away_team']) + list(away_games['home_team'])\n",
    "    \n",
    "    team_stats.append({\n",
    "        'team': team,\n",
    "        'games': total_games,\n",
    "        'wins': home_wins + away_wins,\n",
    "        'simple_win_pct': (home_wins + away_wins) / total_games if total_games > 0 else 0,\n",
    "        'point_diff_avg': (home_diff + away_diff) / total_games if total_games > 0 else 0,\n",
    "        'network_rating': network_ratings.get(team, 0.5),\n",
    "        'opponents': opponents\n",
    "    })\n",
    "\n",
    "df_teams = pd.DataFrame(team_stats)\n",
    "\n",
    "# Calculate SOS metrics\n",
    "win_pct_map = df_teams.set_index('team')['simple_win_pct'].to_dict()\n",
    "df_teams['simple_sos'] = df_teams['opponents'].apply(\n",
    "    lambda opps: np.mean([win_pct_map.get(o, 0.5) for o in opps])\n",
    ")\n",
    "df_teams['network_sos'] = df_teams['opponents'].apply(\n",
    "    lambda opps: np.mean([network_ratings.get(o, 0.5) for o in opps])\n",
    ")\n",
    "\n",
    "df_teams = df_teams.drop('opponents', axis=1).sort_values('network_rating', ascending=False)\n",
    "df_teams.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-ratings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "corr_win_pct = df_teams['network_rating'].corr(df_teams['simple_win_pct'])\n",
    "corr_point_diff = df_teams['network_rating'].corr(df_teams['point_diff_avg'])\n",
    "corr_sos = df_teams['network_sos'].corr(df_teams['simple_sos'])\n",
    "\n",
    "print(\"Correlation Analysis:\")\n",
    "print(f\"  Network Rating vs Win%: {corr_win_pct:.3f}\")\n",
    "print(f\"  Network Rating vs Point Diff: {corr_point_diff:.3f}\")\n",
    "print(f\"  Network SOS vs Simple SOS: {corr_sos:.3f}\")\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].scatter(df_teams['simple_win_pct'], df_teams['network_rating'], alpha=0.7)\n",
    "axes[0].set_xlabel('Simple Win %')\n",
    "axes[0].set_ylabel('Network Rating')\n",
    "axes[0].set_title(f'Network Rating vs Win % (r={corr_win_pct:.3f})')\n",
    "\n",
    "axes[1].scatter(df_teams['point_diff_avg'], df_teams['network_rating'], alpha=0.7)\n",
    "axes[1].set_xlabel('Avg Point Differential')\n",
    "axes[1].set_ylabel('Network Rating')\n",
    "axes[1].set_title(f'Network Rating vs Point Diff (r={corr_point_diff:.3f})')\n",
    "\n",
    "axes[2].scatter(df_teams['simple_sos'], df_teams['network_sos'], alpha=0.7)\n",
    "axes[2].set_xlabel('Simple SOS')\n",
    "axes[2].set_ylabel('Network SOS')\n",
    "axes[2].set_title(f'Network SOS vs Simple SOS (r={corr_sos:.3f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tier-header",
   "metadata": {},
   "source": [
    "## Phase 5: Network-Based Tier Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classify-tiers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify tiers\n",
    "q75_simple, q25_simple = df_teams['simple_win_pct'].quantile([0.75, 0.25])\n",
    "q75_network, q25_network = df_teams['network_rating'].quantile([0.75, 0.25])\n",
    "\n",
    "df_teams['simple_tier'] = df_teams['simple_win_pct'].apply(\n",
    "    lambda x: 'Elite' if x >= q75_simple else ('Bottom' if x <= q25_simple else 'Mid')\n",
    ")\n",
    "df_teams['network_tier'] = df_teams['network_rating'].apply(\n",
    "    lambda x: 'Elite' if x >= q75_network else ('Bottom' if x <= q25_network else 'Mid')\n",
    ")\n",
    "\n",
    "print(\"Tier Classification Comparison:\")\n",
    "print(f\"\\nSimple thresholds: Elite >= {q75_simple:.3f}, Bottom <= {q25_simple:.3f}\")\n",
    "print(f\"Network thresholds: Elite >= {q75_network:.3f}, Bottom <= {q25_network:.3f}\")\n",
    "\n",
    "# Agreement matrix\n",
    "agreement = pd.crosstab(df_teams['simple_tier'], df_teams['network_tier'], margins=True)\n",
    "print(f\"\\nTier Agreement (rows=Simple, cols=Network):\")\n",
    "print(agreement)\n",
    "\n",
    "# Disagreements\n",
    "disagreements = df_teams[df_teams['simple_tier'] != df_teams['network_tier']]\n",
    "print(f\"\\nTeams with different classification ({len(disagreements)}):\\n\")\n",
    "print(disagreements[['team', 'simple_win_pct', 'network_rating', 'simple_sos', 'network_sos', \n",
    "                     'simple_tier', 'network_tier']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-opp-header",
   "metadata": {},
   "source": [
    "## Phase 6: Multi-Hop Common Opponent Analysis\n",
    "\n",
    "NBA's dense schedule allows deeper path exploration (max_hops=3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multi-hop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_opponent_paths(G, team_a, team_b, max_hops=3):\n",
    "    \"\"\"Find all paths through common opponents.\"\"\"\n",
    "    G_undirected = G.to_undirected()\n",
    "    \n",
    "    if team_a not in G or team_b not in G:\n",
    "        return []\n",
    "    \n",
    "    paths = []\n",
    "    try:\n",
    "        for path in nx.all_simple_paths(G_undirected, team_a, team_b, cutoff=max_hops + 1):\n",
    "            if len(path) > 2:\n",
    "                paths.append(path)\n",
    "    except nx.NetworkXNoPath:\n",
    "        pass\n",
    "    \n",
    "    return paths\n",
    "\n",
    "def evaluate_matchup_via_paths(G, team_a, team_b, ratings, max_hops=3):\n",
    "    \"\"\"Evaluate teams through common opponent network.\"\"\"\n",
    "    paths = find_common_opponent_paths(G, team_a, team_b, max_hops)\n",
    "    \n",
    "    if not paths:\n",
    "        return None, 0, []\n",
    "    \n",
    "    a_total_score = 0\n",
    "    b_total_score = 0\n",
    "    total_weight = 0\n",
    "    path_details = []\n",
    "    \n",
    "    for path in paths:\n",
    "        intermediates = path[1:-1]\n",
    "        a_path_score = 0\n",
    "        b_path_score = 0\n",
    "        path_weight = 0\n",
    "        \n",
    "        for intermediate in intermediates:\n",
    "            int_rating = ratings.get(intermediate, 0.5)\n",
    "            \n",
    "            # Team A's performance\n",
    "            if G.has_edge(team_a, intermediate):\n",
    "                margin = G[team_a][intermediate].get('avg_margin', 0)\n",
    "                a_path_score += margin * int_rating\n",
    "            elif G.has_edge(intermediate, team_a):\n",
    "                margin = G[intermediate][team_a].get('avg_margin', 0)\n",
    "                a_path_score -= margin * int_rating\n",
    "            \n",
    "            # Team B's performance\n",
    "            if G.has_edge(team_b, intermediate):\n",
    "                margin = G[team_b][intermediate].get('avg_margin', 0)\n",
    "                b_path_score += margin * int_rating\n",
    "            elif G.has_edge(intermediate, team_b):\n",
    "                margin = G[intermediate][team_b].get('avg_margin', 0)\n",
    "                b_path_score -= margin * int_rating\n",
    "            \n",
    "            path_weight += int_rating\n",
    "        \n",
    "        if path_weight > 0:\n",
    "            a_total_score += a_path_score\n",
    "            b_total_score += b_path_score\n",
    "            total_weight += path_weight\n",
    "            \n",
    "            path_details.append({\n",
    "                'path': ' -> '.join(path),\n",
    "                'hops': len(path) - 2,\n",
    "                'a_score': a_path_score / path_weight,\n",
    "                'b_score': b_path_score / path_weight\n",
    "            })\n",
    "    \n",
    "    if total_weight == 0:\n",
    "        return None, 0, []\n",
    "    \n",
    "    edge = (a_total_score - b_total_score) / total_weight\n",
    "    return edge, len(paths), path_details\n",
    "\n",
    "# Example matchup\n",
    "top_team = df_teams.iloc[0]['team']\n",
    "bottom_team = df_teams.iloc[-1]['team']\n",
    "\n",
    "edge, num_paths, details = evaluate_matchup_via_paths(G, top_team, bottom_team, network_ratings, CONFIG['max_hops'])\n",
    "\n",
    "print(f\"Matchup Analysis: {top_team} vs {bottom_team}\")\n",
    "print(f\"Paths found: {num_paths}\")\n",
    "print(f\"Common opponent edge: {edge:.2f} ({'favors ' + top_team if edge > 0 else 'favors ' + bottom_team})\")\n",
    "\n",
    "# Path breakdown by hops\n",
    "if details:\n",
    "    path_df = pd.DataFrame(details)\n",
    "    print(f\"\\nPaths by hop count:\")\n",
    "    print(path_df.groupby('hops').size())\n",
    "    print(f\"\\nSample paths:\")\n",
    "    for d in details[:3]:\n",
    "        print(f\"  {d['path']} ({d['hops']}-hop)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coverage-header",
   "metadata": {},
   "source": [
    "## Phase 7: Coverage Analysis by Network Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coverage-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate handicap coverage\n",
    "handicaps = [0, 5, 7, 9, 11, 13]\n",
    "\n",
    "for h in handicaps:\n",
    "    df[f'home_covers_{h}pt'] = (df['spread_result_difference'] + h) >= 0\n",
    "    df[f'away_covers_{h}pt'] = df['spread_result_difference'] <= h\n",
    "\n",
    "# Analyze coverage by tier\n",
    "results = []\n",
    "\n",
    "for h in handicaps:\n",
    "    for tier_type in ['simple_tier', 'network_tier']:\n",
    "        for tier in ['Elite', 'Mid', 'Bottom']:\n",
    "            tier_teams = df_teams[df_teams[tier_type] == tier]['team'].tolist()\n",
    "            \n",
    "            total_games = 0\n",
    "            total_covers = 0\n",
    "            \n",
    "            for team in tier_teams:\n",
    "                hg = df[df['home_team'] == team]\n",
    "                total_games += len(hg)\n",
    "                total_covers += hg[f'home_covers_{h}pt'].sum()\n",
    "                \n",
    "                ag = df[df['away_team'] == team]\n",
    "                total_games += len(ag)\n",
    "                total_covers += ag[f'away_covers_{h}pt'].sum()\n",
    "            \n",
    "            results.append({\n",
    "                'handicap': h,\n",
    "                'tier_type': tier_type,\n",
    "                'tier': tier,\n",
    "                'games': total_games,\n",
    "                'covers': total_covers,\n",
    "                'cover_pct': total_covers / total_games if total_games > 0 else 0\n",
    "            })\n",
    "\n",
    "df_coverage = pd.DataFrame(results)\n",
    "\n",
    "print(\"Coverage % by Tier Type and Handicap:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for tier_type in ['simple_tier', 'network_tier']:\n",
    "    print(f\"\\n{tier_type.replace('_', ' ').title()}:\")\n",
    "    pivot = df_coverage[df_coverage['tier_type'] == tier_type].pivot(\n",
    "        index='handicap', columns='tier', values='cover_pct'\n",
    "    )[['Elite', 'Mid', 'Bottom']]\n",
    "    print((pivot * 100).round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot coverage comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "colors = {'Elite': '#2ecc71', 'Mid': '#f39c12', 'Bottom': '#e74c3c'}\n",
    "\n",
    "for idx, tier_type in enumerate(['simple_tier', 'network_tier']):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for tier in ['Elite', 'Mid', 'Bottom']:\n",
    "        data = df_coverage[(df_coverage['tier_type'] == tier_type) & (df_coverage['tier'] == tier)]\n",
    "        ax.plot(data['handicap'], data['cover_pct'] * 100, \n",
    "                marker='o', label=tier, color=colors[tier], linewidth=2)\n",
    "    \n",
    "    ax.axhline(y=50, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Handicap Points')\n",
    "    ax.set_ylabel('Coverage %')\n",
    "    ax.set_title(f'{tier_type.replace(\"_\", \" \").title()}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('NBA: Coverage by Tier Classification Method', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"NBA NETWORK STRENGTH ANALYSIS: SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n1. DATA\")\n",
    "print(f\"   - Games analyzed: {len(df)}\")\n",
    "print(f\"   - Teams: {len(all_teams)}\")\n",
    "print(f\"   - Network edges: {G.number_of_edges()}\")\n",
    "print(f\"   - Avg games per team: {(len(df)*2)/len(all_teams):.0f}\")\n",
    "\n",
    "print(f\"\\n2. NETWORK RATING VALIDATION\")\n",
    "print(f\"   - Correlation with Win%: {corr_win_pct:.3f}\")\n",
    "print(f\"   - Correlation with Point Diff: {corr_point_diff:.3f}\")\n",
    "print(f\"   - Network SOS vs Simple SOS: {corr_sos:.3f}\")\n",
    "\n",
    "print(f\"\\n3. TIER CLASSIFICATION\")\n",
    "tier_agreement = (df_teams['simple_tier'] == df_teams['network_tier']).mean() * 100\n",
    "print(f\"   - Agreement rate: {tier_agreement:.1f}%\")\n",
    "print(f\"   - Disagreements: {len(disagreements)} teams\")\n",
    "\n",
    "print(f\"\\n4. MULTI-HOP ANALYSIS\")\n",
    "print(f\"   - Max hops: {CONFIG['max_hops']}\")\n",
    "print(f\"   - Sample paths found: {num_paths}\")\n",
    "\n",
    "print(f\"\\n5. COVERAGE BY TIER (9pt handicap - NBA standard)\")\n",
    "for tier_type in ['simple_tier', 'network_tier']:\n",
    "    print(f\"   {tier_type.replace('_', ' ').title()}:\")\n",
    "    for tier in ['Elite', 'Mid', 'Bottom']:\n",
    "        pct = df_coverage[(df_coverage['tier_type'] == tier_type) & \n",
    "                         (df_coverage['tier'] == tier) &\n",
    "                         (df_coverage['handicap'] == 9)]['cover_pct'].values[0] * 100\n",
    "        print(f\"      {tier}: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-ratings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export team data\n",
    "export_df = df_teams[['team', 'games', 'wins', 'simple_win_pct', 'network_rating', \n",
    "                      'point_diff_avg', 'simple_sos', 'network_sos', \n",
    "                      'simple_tier', 'network_tier']].copy()\n",
    "\n",
    "export_file = Path().resolve().parent / 'data' / 'results' / 'nba_network_ratings.csv'\n",
    "export_df.to_csv(export_file, index=False)\n",
    "print(f\"Exported team ratings to: {export_file}\")\n",
    "\n",
    "export_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}